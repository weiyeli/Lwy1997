## 常见编码总结：Unicode、UTF、ISO 8859-1等

我们最初学习计算机的时候，都学过ASCII编码。但是为了表示各种各样的语言，在计算机技术的发展过程中，逐渐出现了很多不同标准的编码格式，重要的有Unicode、UTF、ISO 8859-1和中国人经常使用的GB2312、BIG5、GBK等。

## 1. ASCII/ISO 8859-1

计算机世界中最早的编码应数 ANSI 的“ASCII”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。ASCII是7位编码，能表示128个字符。

后来计算机发展越来越广泛，为了可以在计算机中保存更多的文字和符号，启用了从128到255的字符，被称为”扩展字符集”。这就是ISO 8859-1编码，属于单字节编码，应用于拉丁文系列。显然，ISO 8859-1最多能表示的字符范围是0-255（编码范围是0x00-0xFF），其中0x00-0x7F之间完全和ASCII一致，因此向下兼容ASCII。除ASCII收录的字符外，ISO-8859-1收录的字符还包括西欧语言、希腊语、泰语、阿拉伯语、希伯来语对应的文字符号。欧元符号等出现的比较晚，没有被收录在ISO 8859-1当中。

很明显，ISO 8859-1编码表示的字符范围很窄，例如无法表示中文字符。但是由于ISO-8859-1编码范围使用了单字节内的所有空间，在支持ISO 8859-1的系统中传输和存储其他任何编码的字节流都不会被抛弃。换言之，把其他任何编码的字节流当作ISO-8859-1编码看待都没有问题。这是个很重要的特性，所以很多情况下（如很多协议传输数据时）都使用ISO 8859-1编码。我们可以这么说，ASCII编码是一个7位的容器，ISO 8859-1编码是一个8位的容器。

比如，虽然“中文”两个字符就不存在ISO 8859-1编码，但可以用iso8859-1编码来“表示”。通过查询下文将要介绍的GB2312编码表，“中文”应该是"d6d0 cec4"两个字符，使用ISO 8859-1编码来“表示”的时候则将它拆开为4个字节来表示，即"d6 d0  ce c4"（事实上，在进行存储的时候，也是以字节为单位处理的）。如果使用Unicode编码，则表示为"4e2d 6587"；使用UTF编码，则是6个字节"e4 b8 ad  e6 96 87"。很明显，这种使用ISO 8869-1对汉字进行表示的方法还需要以另一种编码为基础。

有些环境下，将ISO 8859-1写作Latin-1。

## 2. 汉字编码 GB2312/BIG5/GBK/GB18030

中国的常用汉字有6000多个，如何保存呢？中华人民共和国政府制定GB2312标准是把ISO 8859-1编码中那些127号之后的奇异符号们直接取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在GB2312编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。

GB2312是汉字的国标码，也是简体汉字编码规范。其表示汉字时是双字节编码，但也兼容单字节的ASCII编码（0-127），因此是**变长**编码系统。与此对应的还有中华民国政府制定的BIG5，是繁体汉字的编码规范。所谓的繁体中文Windows，简体中文Windows，指的就是采用BIG5和GB2312编码格式的操作系统。这两种编码方式不兼容，如果使用一种编码的文本阅读器来读另一种编码的文本，就会出现乱码。比如在简体中文Windows上读BIG5编码的文件，就是乱码，反之亦然。使用简体浏览器浏览的时候，到了繁体中文网站，如果不改变码制，也是乱码。

但是中国的汉字实在太多了，GB2312，BIG5所包含的汉字数量也不足，比如朱总理的名字中间那个字一般就打不出。于是又有了**GBK大字符集**，简而言之就是将所有亚洲文字的双字节字符，包括简体中文，繁体中文，日语，韩语等，都使用一种格式编码，这样就能够做到在所有的语言平台上面兼容。GBK编码是兼**容GB2312编码**的，因此也是**变长编码**（双字节）。但GBK编码中的2字节表示的字符不再要求低字节一定是127号之后的内码，只要高字节是大于127就固定表示这是一个汉字的开始，不管低字节是不是扩展字符集里的内容。GBK大字符集包含的汉字数量比GB2312和BIG5多的多了，目前足够使用。

后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，**GBK** 扩成了 **GB18030**。GB 18030 与 GB 2312-1980 和 GBK 都兼容，是**一二四字节变长编码系统**，也是目前最新最全的内码字集。

## 3. Unicode

Unicode是Unicode.org制定的编码标准，目前得到了绝大部分操作系统和编程语言的支持。Unicode.org官方对Unicode的定义是：Unicode provides a unique number for every character。可见，Unicode所做的是为每个字符定义了一个相应的数字表示。比如，"a"的Unicode值是0x0061,“一”的Unicde值是0x4E00，这是最简单的情况，每个字符用2个字节表示。

Unicode是最统一的编码，可以用来表示所有语言的字符，而且是**定长**双字节（如果考虑辅助平面，也有四字节的）编码，包括英文字母在内，都以双字节表示，所以它是不兼容ISO 8859-1编码的。不过，相对于ISO 8859-1中所编码的字符来说，Unicode编码只是在前面增加了一个全0字节，例如字母a的Unicode编码为"00 61"。和GB2312/GBK等非定长编码相比，定长编码便于计算机处理，而Unicode又可以用来表示所有字符，所以在很多软件内部是使用Unicode编码来处理的，比如java。

Unicode的编码空间从U+0000到U+10FFFF，共有1,112,064个码位（code point）可用来映射字符. Unicode的编码空间可以划分为17个平面（plane），每个平面包含216（65,536）个码位。17个平面的码位可表示为从U+xx0000到U+xxFFFF， 其中xx表示十六进制值从00(16) 到10(16)，共计17个平面。第一个平面称为**基本多语言平面**（Basic Multilingual Plane, **BMP**），或称第零平面（Plane 0），码位从U+0000至U+FFFF，包含了最常用的字符。其他平面称为**辅助平面**(Supplementary Planes)。

对于在Unicode基本多语言平面定义的字符（无论是拉丁字母、汉字或其他文字或符号），一律使用2字节储存，但是从U+D800到U+DFFF之间的码位区段是永久保留不映射到任何Unicode字符的。而在辅助平面定义的字符，即从U+010000到U+10FFFF的码位，则（UTF-16的做法是）以代理对（surrogate pair）的形式，将其拆分成两个2字节（位于0xD800-0xDFFF区段）共4字节的值来储存。进行代理对映射的方法本文就不深入讨论了，有兴趣的可以自行搜索。

## 4. UTF

考虑到Unicode编码不兼容ISO 8859-1编码，而且容易占用更多的空间：因为对于英文字母，Unicode也需要两个字节来表示，所以Unicode不便于传输和存储。因此而产生了UTF编码。

UTF 是 Unicode Translation Format，即把Unicode转做某种格式的意思。事实上可以这么认为，**Unicode是一种编码方式，和ACSII是同一个概念，而UTF是一种存储方式（格式）**。

那么，UTF是如何做这种格式转换的呢？

**UTF-32**

Unicode.org定义了百万个以上的字符，如果将所有的字符用统一的格式表示，需要的是4个字节。"a"的Unicode表示就会变成0x00000061，而“一”的Unicode值是0x00004E00。实际上，这就是UTF-32，也是Linux操作系统上所使用的Unicode方案，也是一种定长编码。其缺点很显然是造成了空间的巨大浪费，从而非常没有效率，因此没有UTF-8和UTF-16使用的频繁。

**UTF-16**

但是，上文已经提到，Unicode基本多语言平面的字符只使用2个字节就可以表示了，真正需要扩展到4个字节来表示的字符少之又少。所以使用2个字节来表示Unicode代码是一种很自然的选择，例如英文的Unicode范围是0x0000-0x007F，中文的Unicode范围是0x4E00-0x9F**。对于那些扩展平面中需要4个字节才能表示的字符，UTF-16使用一种代理的手法来扩展（使用了基本多语言平面保留的0xD800-0xDFFF区段，表示这是一个代理，从而用2个16位码元组成一个字符）。这样的好处是大量的节约了存取空间，也提高了处理的速度。这种Unicode表示方法就是UTF-16，显然，UTF-16需要1个或者2个16位长的码元（也即2字节或4字节）来表示，因此UTF-16是一个变长表示。一般在Windows平台上，提到Unicode，那就是指UTF-16了。

UTF-16有一个著名的Endian的问题（名称来自《格列夫游记》），即UTF16-LE和UTF16-BE，LE指Little Endian，而BE指Big Endian。关于这方面的信息，网上有很多相关的帖子。这与计算机的CPU架构有一定关系，我们一般的X86系统都是Little Endian的，可以认为UTF16就是UTF16-LE。

另外，UTF有一个BOM（Byte Order Mark）的问题。在Unicode编码中有一个被称为"Zero-Width No-Break Space (ZWNBSP)"的字符，它的编码是0xFEFF。而0xFEFF在是一个实际中不存在的字符，所以**不应该出现在实际传输中**。UCSUCS (Unicode Character Set) 规范建议我们在传输字节流前，先传输字符"ZWNBSP"。这样如果接收者收到FEFF，就表明这个字节流是Big-Endian的；如果收到FFFE，就表明这个字节流是Little- Endian的。因此字符"ZWNBSP"又被称作BOM。

**UTF-8**

UTF-16的最大好处在于大部分字符都以固定长度的2字节储存（如果考虑到Unicode辅助平面UTF-16也是变长编码），但UTF-16却无法兼容于ASCII编码。由于对于欧洲和北美，实际上使用的编码范围在0x0000-0x00FF之间，只需要一个字节就可以表示所有的字符。即使是使用UTF16来作为内存的存取方式，还是会带来巨大的空间浪费，因此就有了UTF8的编码方式。

UTF-8编码是最灵活的UTF编码形式，即兼容ISO 8859-1的编码，同时也可以用来表示所有语言的字符。显然，UTF-8编码是变长编码，每一个字符的长度从1-6个字节不等。另外，UTF编码自带简单的校验功能。

UTF-8编码中，对于只需要1个字节的字符，就使用一个字节；对于中日韩等Unicode中需要两个字节才能表示的字符，则通过一个 UTF16 – UTF8 的算法实现相互之间的转换（转换后的UTF-8一般需要3个字节），而对于Unicode中需要4个字节才能表示的字符，UTF-8根据需要可以扩展到6个字节来表示一个字符。UTF8使用的算法很有意思，大致映射关系如下：

UTF-32                                                         UTF8
0x00000000 - 0x0000007F         0xxxxxxx
0x00000080 - 0x000007FF          110xxxxx 10xxxxxx
0x00000800 - 0x0000FFFF          1110xxxx 10xxxxxx 10xxxxxx
0x00010000 - 0x001FFFFF           11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
0x00200000 - 0x03FFFFFF           111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
0x04000000 - 0x7FFFFFFF           1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx

可以发现这和IP的分址算法很是相像，详细的映射规则可以参考[这里](http://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&item_id=IWS-AppendixA)。

由于UTF-8可以方便的转换为UTF16和UTF32（不需要码表，执行一个转换算法即可，在Unicode.org上提供了[C代码](http://ftp//www.unicode.org/Public/PROGRAMS/CVTUTF/)）。而且UTF-8在每个操作系统平台上的实现都是一样的，也不存在跨平台的问题，所以UTF-8成为跨平台的Unicode很好的解决方案。当然，对于中文来说，由于每个字符需要3个字节才能表示，还是有点浪费的。

注意，虽然说UTF-8是为了使用更少的空间而使用的，但那只是相对于Unicode编码来说，如果已经知道是汉字，则使用GB2312/GBK无疑是最节省的。不过另一方面，值得说明的是，对于中文网页，虽然UTF-8编码对汉字使用3个字节，UTF8编码也会比UTF-16编码节省，因为网页HTML中包含了更多的英文字符。

UTF-8 是不需要BOM来表明字节顺序，但可以用BOM来表明编码方式。字符"ZWNBSP"即“0xFEFF”的UTF-8编码是EF BB BF（根据上表转换关系）。所以如果接收者收到以EF BB BF开头的字节流，就知道这是通知其收到的是UTF-8编码了。

Windows系统就是用BOM来标记文本文件的编码方式的。用UltraEdit等编辑器的16进制编辑模式查看UTF-8编码的文件，都是EF BB BF开头的，说明都是带BOM的。参照下面的GB2312/GBK的编码，可以解释为什么在出现编码问题时，经常看到这三个汉字“锘匡豢”：

（完）

**参考资料：**

[1] TechGuru: http://tunps.com/link-and-script-goes-under-body-tag

[2] 网页编码就是那点事|潜行者m：http://www.qianxingzhem.com/post-1499.html